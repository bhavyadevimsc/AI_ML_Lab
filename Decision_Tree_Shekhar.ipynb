{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jkVzGxEKCGNe"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lwTHabB0COXB"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, value=None, results=None, true_branch=None, false_branch=None):\n",
    "        self.feature = feature  # Feature to split on\n",
    "        self.value = value      # Value of the feature to split on\n",
    "        self.results = results  # Stores class labels if node is a leaf node\n",
    "        self.true_branch = true_branch  # Branch for values that are True for the feature\n",
    "        self.false_branch = false_branch  # Branch for values that are False for the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AJWNwddyCWhN"
   },
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    counts = np.bincount(data)\n",
    "    probabilities = counts / len(data)\n",
    "    entropy = -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q1arZDIQCs4p"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, feature, value):\n",
    "    true_indices = np.where(X[:, feature] <= value)[0]\n",
    "    false_indices = np.where(X[:, feature] > value)[0]\n",
    "    true_X, true_y = X[true_indices], y[true_indices]\n",
    "    false_X, false_y = X[false_indices], y[false_indices]\n",
    "    return true_X, true_y, false_X, false_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YXoa6rn9C3O_"
   },
   "outputs": [],
   "source": [
    "def build_tree(X, y):\n",
    "    if len(set(y)) == 1:\n",
    "        return Node(results=y[0])\n",
    "\n",
    "    best_gain = 0\n",
    "    best_criteria = None\n",
    "    best_sets = None\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    current_entropy = entropy(y)\n",
    "\n",
    "    for feature in range(n_features):\n",
    "        feature_values = set(X[:, feature])\n",
    "        for value in feature_values:\n",
    "            true_X, true_y, false_X, false_y = split_data(X, y, feature, value)\n",
    "            true_entropy = entropy(true_y)\n",
    "            false_entropy = entropy(false_y)\n",
    "            p = len(true_y) / len(y)\n",
    "            gain = current_entropy - p * true_entropy - (1 - p) * false_entropy\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_criteria = (feature, value)\n",
    "                best_sets = (true_X, true_y, false_X, false_y)\n",
    "\n",
    "    if best_gain > 0:\n",
    "        true_branch = build_tree(best_sets[0], best_sets[1])\n",
    "        false_branch = build_tree(best_sets[2], best_sets[3])\n",
    "        return Node(feature=best_criteria[0], value=best_criteria[1], true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "    return Node(results=y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uJ4XnVbnDDT2"
   },
   "outputs": [],
   "source": [
    "def predict(tree, sample):\n",
    "    if tree.results is not None:\n",
    "        return tree.results\n",
    "    else:\n",
    "        branch = tree.false_branch\n",
    "        if sample[tree.feature] <= tree.value:\n",
    "            branch = tree.true_branch\n",
    "        return predict(branch, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "17XhrSiLDH0e"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([1, 1, 0, 0])\n",
    "\n",
    "# Building the tree\n",
    "decision_tree = build_tree(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6y-AnthEDOD4",
    "outputId": "7215accb-ddc8-4458-f88b-d5cf7fce260c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sample [1 0]: 1\n"
     ]
    }
   ],
   "source": [
    "sample = np.array([1, 0])\n",
    "prediction = predict(decision_tree, sample)\n",
    "print(f\"Prediction for sample {sample}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for manipulating the csv data\n",
    "import numpy as np #for mathematical calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play Tennis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook Temperature Humidity    Wind Play Tennis\n",
       "0     Sunny         Hot     High    Weak          No\n",
       "1     Sunny         Hot     High  Strong          No\n",
       "2  Overcast         Hot     High    Weak         Yes\n",
       "3      Rain        Mild     High    Weak         Yes\n",
       "4      Rain        Cool   Normal    Weak         Yes"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_m = pd.read_csv(\"PlayTennis_Train.csv\") #importing the dataset from the disk\n",
    "train_data_m.head() #viewing some row of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_entropy(train_data, label, class_list):\n",
    "    total_row = train_data.shape[0] #the total size of the dataset\n",
    "    total_entr = 0\n",
    "    \n",
    "    for c in class_list: #for each class in the label\n",
    "        total_class_count = train_data[train_data[label] == c].shape[0] #number of the class\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n",
    "        total_entr += total_class_entr #adding the class entropy to the total entropy of the dataset\n",
    "    \n",
    "    return total_entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "    \n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c \n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count #probability of the class\n",
    "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\n",
    "        entropy += entropy_class\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0\n",
    "    \n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #filtering rows with that feature_value\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) #calculcating entropy for the feature value\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\n",
    "        \n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info #calculating information gain by subtracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "    feature_list = train_data.columns.drop(label) #finding the feature names in the dataset\n",
    "                                            #N.B. label is not a feature, so dropping it\n",
    "    max_info_gain = -1\n",
    "    max_info_feature = None\n",
    "    \n",
    "    for feature in feature_list:  #for each feature in the dataset\n",
    "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
    "        if max_info_gain < feature_info_gain: #selecting feature name with highest information gain\n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature\n",
    "            \n",
    "    return max_info_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) #dictionary of the count of unqiue feature value\n",
    "    tree = {} #sub tree or node\n",
    "    \n",
    "    for feature_value, count in feature_value_count_dict.items():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #dataset with only feature_name = feature_value\n",
    "        \n",
    "        assigned_to_node = False #flag for tracking feature_value is pure class or not\n",
    "        for c in class_list: #for each class\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] #count of class c\n",
    "\n",
    "            if class_count == count: #count of (feature_value = count) of class (pure class)\n",
    "                tree[feature_value] = c #adding node to the tree\n",
    "                train_data = train_data[train_data[feature_name] != feature_value] #removing rows with feature_value\n",
    "                assigned_to_node = True\n",
    "        if not assigned_to_node: #not pure class\n",
    "            tree[feature_value] = \"?\" #as feature_value is not a pure class, it should be expanded further, \n",
    "                                      #so the branch is marking with ?\n",
    "            \n",
    "    return tree, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
    "    if train_data.shape[0] != 0: #if dataset becomes enpty after updating\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list) #most informative feature\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list) #getting tree node and updated dataset\n",
    "        next_root = None\n",
    "        \n",
    "        if prev_feature_value != None: #add to intermediate node of the tree\n",
    "            root[prev_feature_value] = dict()\n",
    "            root[prev_feature_value][max_info_feature] = tree\n",
    "            next_root = root[prev_feature_value][max_info_feature]\n",
    "        else: #add to root of the tree\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]\n",
    "        \n",
    "        for node, branch in list(next_root.items()): #iterating the tree node\n",
    "            if branch == \"?\": #if it is expandable\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node] #using the updated dataset\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list) #recursive call with updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(train_data_m, label):\n",
    "    train_data = train_data_m.copy() #getting a copy of the dataset\n",
    "    tree = {} #tree which will be updated\n",
    "    class_list = train_data[label].unique() #getting unqiue classes of the label\n",
    "    make_tree(tree, None, train_data, label, class_list) #start calling recursion\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = id3(train_data_m, 'Play Tennis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Outlook': {'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}},\n",
       "  'Overcast': 'Yes',\n",
       "  'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, instance):\n",
    "    if not isinstance(tree, dict): #if it is leaf node\n",
    "        return tree #return the value\n",
    "    else:\n",
    "        root_node = next(iter(tree)) #getting first key/feature name of the dictionary\n",
    "        feature_value = instance[root_node] #value of the feature\n",
    "        if feature_value in tree[root_node]: #checking the feature value in current tree node\n",
    "            return predict(tree[root_node][feature_value], instance) #goto next feature\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tree, test_data_m, label):\n",
    "    correct_preditct = 0\n",
    "    wrong_preditct = 0\n",
    "    for index, row in test_data_m.iterrows(): #for each row in the dataset\n",
    "        result = predict(tree, test_data_m.iloc[index]) #predict the row\n",
    "        if result == test_data_m[label].iloc[index]: #predicted value and expected value is same or not\n",
    "            correct_preditct += 1 #increase correct count\n",
    "        else:\n",
    "            wrong_preditct += 1 #increase incorrect count\n",
    "    accuracy = correct_preditct / (correct_preditct + wrong_preditct) #calculating accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_m = pd.read_csv(\"PlayTennis_Test.csv\") #importing test dataset into dataframe\n",
    "\n",
    "accuracy = evaluate(tree, test_data_m, 'Play Tennis') #evaluating the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
